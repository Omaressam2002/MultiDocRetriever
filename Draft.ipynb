{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "305336d6-56f1-4a43-a3e3-2ca2c452c7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters :\n",
    "# chunking , different chunking for each type\n",
    "# embedding modules\n",
    "# reranking module\n",
    "\n",
    "\n",
    "\n",
    "# ✅ 1. embed_documents(texts: List[str]) -> List[List[float]]\n",
    "# Takes a list of strings (your text chunks).\n",
    "# Returns a list of embedding vectors (each a list or NumPy array of floats).\n",
    "# The number of output vectors must equal the number of input texts.\n",
    "# ✅ 2. embed_query(text: str) -> List[float]\n",
    "\n",
    "# Create task from the query and then retrieve based on it\n",
    "\n",
    "# so you got to use the retrieve from task as a tool\n",
    "\n",
    "# paraphrase-MiniLM-L6-v2 , Instructor-XL / Instructor-Large,  Instructor-XL / Instructor-Large\n",
    "# retrieve answers in the first place\n",
    "# cross-encoder/ms-marco-MiniLM-L-6-v2 => reranker for q - a relevance\n",
    "# maybe use bge embeddings with BAAI/bge-reranker-large\n",
    "\n",
    "\n",
    "# ACNE or dual encoder :\n",
    "# E5-large-v2 → trained with explicit “query: ... passage: ...” format\n",
    "\n",
    "\n",
    "\n",
    "# use a pipeline and loop again if not good answer?\n",
    "\n",
    "\n",
    "# pipelines to try :\n",
    "# ACNE dual encoders : Approximate Nearest Neighbor Negative Contrastive Estimation for Dense Text Retrieval (ANCE)”, RocketQA, GTR, E5 v2\n",
    "# generate a search query : User Query → LLM reformulates (\"Find passages describing X, not asking about it\")  : Self-rag, RRF + LLM-guided retriever (2024\n",
    "# assymetric encoder : different encoder for each of the query and the knowledge : ColBERT, TART, T5-embed, Dragon+ (2024)\n",
    "# ColBERTv2 — represents documents as multiple token embeddings (instead of one mean vector), improving granularity.\n",
    "\n",
    "# Bonus: You can use the LLM’s feedback to iteratively refine retrieval → this is how Self-RAG achieves much higher precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3210ba61-7a70-4982-bc83-d3813cbd79e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E5\n",
    "# we will use this one and if so\n",
    "# have to add query before each query and a passage in the split docs\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"intfloat/e5-small-v2\")\n",
    "texts = [\n",
    "    \"query: What is the capital of France?\",\n",
    "    \"passage: Paris is the capital and most populous city of France.\",\n",
    "    \"What are you doing here in France?\"\n",
    "]\n",
    "embeddings = model.encode(texts, convert_to_numpy=True, normalize_embeddings=True)\n",
    "\n",
    "class E5Embedder:\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return model.encode(texts, convert_to_numpy=True, normalize_embeddings=True).tolist()\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return model.encode([text], convert_to_numpy=True, normalize_embeddings=True)[0].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd3e48-3df2-4a2f-953e-a319363a1495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "# Compute pairwise cosine similarity\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# Display results\n",
    "print(\"Pairwise cosine similarity:\\n\", np.round(similarity_matrix, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7638cada-2932-481b-99b8-19bea77d3172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TapasTokenizer, TapasForQuestionAnswering\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Load model\n",
    "tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-large-finetuned-wtq\")\n",
    "model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-large-finetuned-wtq\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975049d6-a2ac-468f-80a3-d9e4519a2771",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/tapas-large-finetuned-wtq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40626e41-018b-480f-a961-4f8a663e7a3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow many points did Arsenal score?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Tokenize\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n",
      "File \u001b[0;32m~/pytorch-test/env/lib/python3.9/site-packages/transformers/models/tapas/tokenization_tapas.py:602\u001b[0m, in \u001b[0;36mTapasTokenizer.__call__\u001b[0;34m(self, table, queries, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m    581\u001b[0m         table\u001b[38;5;241m=\u001b[39mtable,\n\u001b[1;32m    582\u001b[0m         queries\u001b[38;5;241m=\u001b[39mqueries,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    600\u001b[0m     )\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 602\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43manswer_coordinates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manswer_coordinates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43manswer_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manswer_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pytorch-test/env/lib/python3.9/site-packages/transformers/models/tapas/tokenization_tapas.py:977\u001b[0m, in \u001b[0;36mTapasTokenizer.encode_plus\u001b[0;34m(self, table, query, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_offsets_mapping:\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    972\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_offset_mapping is not available when using Python tokenizers. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    973\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use this feature, change your tokenizer to one deriving from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    974\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.PreTrainedTokenizerFast.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    975\u001b[0m     )\n\u001b[0;32m--> 977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer_coordinates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manswer_coordinates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manswer_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pytorch-test/env/lib/python3.9/site-packages/transformers/models/tapas/tokenization_tapas.py:1030\u001b[0m, in \u001b[0;36mTapasTokenizer._encode_plus\u001b[0;34m(self, table, query, answer_coordinates, answer_text, add_special_tokens, padding, truncation, max_length, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1025\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   1026\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTAPAS is a question answering model but you have not passed a query. Please be aware that the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1027\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel will probably not behave correctly.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1028\u001b[0m     )\n\u001b[0;32m-> 1030\u001b[0m table_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenize_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m query, query_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_question_tokens(query)\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_for_model(\n\u001b[1;32m   1034\u001b[0m     table,\n\u001b[1;32m   1035\u001b[0m     query,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1052\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m   1053\u001b[0m )\n",
      "File \u001b[0;32m~/pytorch-test/env/lib/python3.9/site-packages/transformers/models/tapas/tokenization_tapas.py:1332\u001b[0m, in \u001b[0;36mTapasTokenizer._tokenize_table\u001b[0;34m(self, table)\u001b[0m\n\u001b[1;32m   1330\u001b[0m     tokenized_row \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m row:\n\u001b[0;32m-> 1332\u001b[0m         tokenized_row\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1333\u001b[0m     tokenized_rows\u001b[38;5;241m.\u001b[39mappend(tokenized_row)\n\u001b[1;32m   1335\u001b[0m token_coordinates \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/pytorch-test/env/lib/python3.9/site-packages/transformers/tokenization_utils.py:651\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    645\u001b[0m     escaped_special_toks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    646\u001b[0m         re\u001b[38;5;241m.\u001b[39mescape(s_tok\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m    647\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m s_tok \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_added_tokens_decoder\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s_tok\u001b[38;5;241m.\u001b[39mspecial \u001b[38;5;129;01mand\u001b[39;00m s_tok\u001b[38;5;241m.\u001b[39mnormalized\n\u001b[1;32m    649\u001b[0m     ]\n\u001b[1;32m    650\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(escaped_special_toks) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)|\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(.+?)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 651\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m split_special_tokens:\n\u001b[1;32m    654\u001b[0m     no_split_token \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/pytorch-test/env/lib/python3.9/re.py:210\u001b[0m, in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msub\u001b[39m(pattern, repl, string, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    204\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "# Example table\n",
    "data = {\n",
    "    \"Team\": [\"Arsenal\", \"Chelsea\", \"Liverpool\"],\n",
    "    \"Points\": [80, 75, 70],\n",
    "    \"Matches\": [38, 38, 38]\n",
    "}\n",
    "table = pd.DataFrame.from_dict(data)\n",
    "\n",
    "# Question\n",
    "query = \"How many points did Arsenal score?\"\n",
    "\n",
    "# Tokenize\n",
    "inputs = tokenizer(table=table, queries=query, return_tensors=\"pt\")\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "logits_agg = outputs.logits_aggregation\n",
    "\n",
    "# Decode answer\n",
    "predicted_answer_coordinates, predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\n",
    "    inputs, logits, logits_agg\n",
    ")\n",
    "answers = []\n",
    "for coordinates in predicted_answer_coordinates:\n",
    "    if len(coordinates) == 1:\n",
    "        answers.append(table.iat[coordinates[0]])\n",
    "print(\"Answer:\", answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b0bf0c-dcb5-47a7-980e-076bc567bddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"./models/zephyr-7b-alpha-local\"\n",
    "tokenizer.save_pretrained(SAVE_DIR)\n",
    "model.save_pretrained(SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a69f0adf-48a0-4c30-b0e6-bb09bec64677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "try:\n",
    "    result = 10 / 0\n",
    "except Exception as e:\n",
    "    write_error_log(\"Division by zero in computation block\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f341e-3f17-41ce-aa40-99cd2ecb9b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"./zephyr-7b-alpha-local\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH, torch_dtype=torch.bfloat16, device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19af888b-1314-4ec2-9c87-8ff346771900",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = textualize(\"./docs/Global_education.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb9eeb9-da53-4e93-a0e8-ff6f9397dbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "embedder = SentenceTransformer(\"intfloat/e5-small-v2\")\n",
    "\n",
    "# example cache\n",
    "query_cache = {\n",
    "    \"What is the capital of France?\": {\n",
    "        \"embedding\": embedder.encode(\"What is the capital of France?\", normalize_embeddings=True),\n",
    "        \"retrieved_docs\": [{\"id\": \"doc_12\"}, {\"id\": \"doc_4\"}]\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_cached_query_result(new_query, threshold=0.9):\n",
    "    new_emb = embedder.encode(new_query, normalize_embeddings=True)\n",
    "    for cached_q, entry in query_cache.items():\n",
    "        sim = util.cos_sim(new_emb, entry[\"embedding\"])[0][0].item()\n",
    "        if sim > threshold:\n",
    "            print(f\"Cache hit! Similar to: {cached_q} (sim={sim:.3f})\")\n",
    "            return entry[\"retrieved_docs\"]\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb638686-c25b-4708-8598-28776431229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=\"YOUR_KEY\")\n",
    "index = pc.Index(\"your-index-name\")\n",
    "\n",
    "# Retrieve vector and metadata by ID\n",
    "response = index.fetch(ids=[\"doc_12\", \"doc_4\"])\n",
    "for id, record in response['vectors'].items():\n",
    "    print(id, record['metadata'], record['values'])\n",
    "for doc in results:\n",
    "    print(doc.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a307ac-ac5f-4d39-bc4d-1792ec0bf115",
   "metadata": {},
   "outputs": [],
   "source": [
    "{ \"query\": \"What is the capital of France?\", \"retrieved_docs\": [ {\"id\": \"doc_12\", \"score\": 0.92}, {\"id\": \"doc_4\", \"score\": 0.88} ] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "255e6b5a-b8c7-47ca-94cb-9ac3f6b8491a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.584671  -3.5387917]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('A padding oracle attack exploits cryptographic padding schemes.', 8.584671),\n",
       " ('An SQL injection attack targets database queries.', -3.5387917)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "\n",
    "# Example query + passages\n",
    "query = \"What is a padding oracle attack?\"\n",
    "passages = [\n",
    "    \"A padding oracle attack exploits cryptographic padding schemes.\",\n",
    "    \"An SQL injection attack targets database queries.\",\n",
    "]\n",
    "\n",
    "# Compute scores\n",
    "scores = model.predict([(query, passage) for passage in passages])\n",
    "print(scores)\n",
    "x = list(zip(passages, scores))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4de8626b-297c-4976-818b-fbef98c654c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A padding oracle attack exploits cryptographic padding schemes.',\n",
       " 'An SQL injection attack targets database queries.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_docs = sorted(x, key=lambda x: x[1], reverse=True)\n",
    "l = [x[0] for x in scored_docs]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e043060-b305-4751-bf51-a9f8f89736b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3awzeen function lel pdfs or text files el zeyada\n",
    "# 3awzeenha telisten kol ma 7ad ye upload ay pdf aw youtube link to the file uploader we te read and index the file content\n",
    "# then 3awzeen ne5aly el stremlit app 1 for youtube and 1 for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c615752-6e3a-4e3f-ae41-2eaab4d87184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next \n",
    "# finish the streamlit app\n",
    "# 1 page for home and another page for chatbot that will have predefined pdfs to be shown and allow to updload another pdf to add to the pinecone\n",
    "# the allow to ask questions and retrieve and add the reference\n",
    "# to add :\n",
    "# history and context\n",
    "# caching\n",
    "# check first by an llm whethter the question needs retrieval ro not\n",
    "# evaluate the answer and its relevance to the reference and might rewrite the query"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
